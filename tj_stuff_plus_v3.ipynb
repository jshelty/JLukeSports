{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tjStuff+ v+3.0\n",
    "\n",
    "##### By: Thomas Nestico ([@TJStats](https://x.com/TJStats))\n",
    "##### Data: MLB (Downloaded via my [MLB Stats API Scraper](https://github.com/tnestico/mlb_scraper))\n",
    "##### [Medium Article](https://medium.com/@thomasjamesnestico/modelling-tjstuff-v3-0-10b48294c7fb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "I downloaded 2020-24 Data using my MLB Stats API Scraper, and wrote it to a CSV file on my local machine. The data can be downloaded at this [link](https://huggingface.co/datasets/nesticot/mlb_data/blob/main/mlb_pitch_data_2020_2024.csv)\n",
    "\n",
    "This notebook uses Polars for its DataFrame Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Load the MLB pitch data from a CSV file into a Polars DataFrame\n",
    "df = pl.read_csv(\"mlb_pitch_data_2020_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Values\n",
    "\n",
    "This project uses Run Values (RV) as the target. Using Baseball Savant's 2024 CSVs, I created a CSV File called 'run_values.csv'. This CSV file hosts the Run Values for specified events from the 2024 MLB Season.\n",
    "\n",
    "These events include:\n",
    "\n",
    "* Pitch-Level Events\n",
    "    * Ball\n",
    "    * Called Strike\n",
    "    * Swinging Strike\n",
    "    * Foul\n",
    "    * Hit By Pitch\n",
    "\n",
    "* Batted Ball Events\n",
    "    * Single\n",
    "    * Double\n",
    "    * Triple\n",
    "    * Home Run\n",
    "    * Field Out\n",
    "\n",
    "Each of these events are assigned a RV which is the average RV of that event for a given count (Balls-Strikes) during the 2024 Season. The following code reassigns the events in the Full Dataset to one of these outcomes and then assigns their specified RV to a column called 'target'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df' is already loaded with necessary pitch data\n",
    "\n",
    "# Define a dictionary to group pitch outcomes relevant to whiff calculation\n",
    "des_dict = {\n",
    "    'Ball': 'ball',\n",
    "    'In play, run(s)': 'hit_into_play',\n",
    "    'In play, out(s)': 'hit_into_play',\n",
    "    'In play, no out': 'hit_into_play',\n",
    "    'Called Strike': 'called_strike',\n",
    "    'Foul': 'foul',\n",
    "    'Swinging Strike': 'swinging_strike',  # Important for whiff\n",
    "    'Blocked Ball': 'ball',\n",
    "    'Swinging Strike (Blocked)': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Tip': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Bunt': 'foul',\n",
    "    'Hit By Pitch': 'hit_by_pitch',\n",
    "    'Pitchout': 'ball',\n",
    "    'Missed Bunt': 'swinging_strike',  # Important for whiff\n",
    "    'Bunt Foul Tip': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Pitchout': 'foul',\n",
    "    'Ball In Dirt': 'ball'\n",
    "}\n",
    "\n",
    "# Define a dictionary to group events together\n",
    "event_dict = {\n",
    "    'game_advisory': None,\n",
    "    'single': 'single',\n",
    "    'walk': 'walk',\n",
    "    np.nan: None,\n",
    "    'strikeout': 'strikeout',  # Relevant for whiff as strikeouts correlate with swinging strikes\n",
    "    'field_out': 'field_out',\n",
    "    'force_out': 'field_out',\n",
    "    'double': 'double',\n",
    "    'hit_by_pitch': 'hit_by_pitch',\n",
    "    'home_run': 'home_run',\n",
    "    'grounded_into_double_play': 'field_out',\n",
    "    'fielders_choice_out': 'field_out',\n",
    "    'fielders_choice': 'field_out',\n",
    "    'field_error': None,\n",
    "    'double_play': 'field_out',\n",
    "    'sac_fly': 'field_out',\n",
    "    'strikeout_double_play': None,\n",
    "    'triple': 'triple',\n",
    "    'caught_stealing_2b': None,\n",
    "    'sac_bunt': 'field_out',\n",
    "    'catcher_interf': None,\n",
    "    'caught_stealing_3b': None,\n",
    "    'sac_fly_double_play': 'field_out',\n",
    "    'triple_play': 'field_out',\n",
    "    'other_out': 'field_out',\n",
    "    'pickoff_3b': None,\n",
    "    'caught_stealing_home': None,\n",
    "    'pickoff_1b': None,\n",
    "    'pickoff_2b': None,\n",
    "    'wild_pitch': None,\n",
    "    'stolen_base_2b': None,\n",
    "    'pickoff_caught_stealing_3b': None,\n",
    "    'pickoff_caught_stealing_2b': None,\n",
    "    'sac_bunt_double_play': None,\n",
    "    'passed_ball': None,\n",
    "    'pickoff_caught_stealing_home': None\n",
    "}\n",
    "\n",
    "# Create a separate dataframe for the relevant whiff data\n",
    "df_whiff = df[['play_description', 'balls', 'strikes', 'is_swing', 'is_whiff']].unique()\n",
    "\n",
    "# Replace play descriptions with the grouped outcomes from des_dict\n",
    "df = df.with_columns(pl.col(\"play_description\").replace_strict(des_dict, default=None))\n",
    "\n",
    "# Join the whiff-related data (df_whiff) with the main dataframe (df) based on the play description, balls, and strikes\n",
    "df = df.join(df_whiff, \n",
    "             left_on=['play_description', 'balls', 'strikes'],\n",
    "             right_on=['play_description', 'balls', 'strikes'], \n",
    "             how='left', \n",
    "             suffix='_whiff')\n",
    "\n",
    "# Convert the boolean columns 'is_swing' and 'is_whiff' to integers\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col('is_swing').is_null()).then(0).otherwise(pl.col('is_swing').cast(pl.Int32)).alias('is_swing_int'),\n",
    "    pl.when(pl.col('is_whiff').is_null()).then(0).otherwise(pl.col('is_whiff').cast(pl.Int32)).alias('is_whiff_int')\n",
    ")\n",
    "\n",
    "# Now, define the target variable:\n",
    "# If the batter swung (is_swing == 1) and missed (is_whiff == 1), mark it as 1 (whiff); otherwise, 0\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col('is_swing_int') == 1)\n",
    "    .then(pl.when(pl.col('is_whiff_int') == 1).then(1).otherwise(0))  # If swung and missed, it's a whiff\n",
    "    .otherwise(0)  # If no swing, not a whiff\n",
    "    .alias('target')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Now df['target'] will contain 1 for whiffs and 0 for non-whiffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load the run values data from CSV\n",
    "df_run_values = pl.read_csv(\"run_values.csv\")\n",
    "\n",
    "# Define a dictionary to group pitch outcomes together\n",
    "des_dict = {\n",
    "    'Ball': 'ball',\n",
    "    'In play, run(s)': 'hit_into_play',\n",
    "    'In play, out(s)': 'hit_into_play',\n",
    "    'In play, no out': 'hit_into_play',\n",
    "    'Called Strike': 'called_strike',\n",
    "    'Foul': 'foul',\n",
    "    'Swinging Strike': 'swinging_strike',  # Important for whiff\n",
    "    'Blocked Ball': 'ball',\n",
    "    'Swinging Strike (Blocked)': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Tip': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Bunt': 'foul',\n",
    "    'Hit By Pitch': 'hit_by_pitch',\n",
    "    'Pitchout': 'ball',\n",
    "    'Missed Bunt': 'swinging_strike',  # Important for whiff\n",
    "    'Bunt Foul Tip': 'swinging_strike',  # Important for whiff\n",
    "    'Foul Pitchout': 'foul',\n",
    "    'Ball In Dirt': 'ball'\n",
    "}\n",
    "\n",
    "# Define a dictionary to group events together\n",
    "event_dict = {\n",
    "    'game_advisory': None,\n",
    "    'single': 'single',\n",
    "    'walk': 'walk',\n",
    "    np.nan: None,\n",
    "    'strikeout': 'strikeout',  # Relevant for whiff as strikeouts correlate with swinging strikes\n",
    "    'field_out': 'field_out',\n",
    "    'force_out': 'field_out',\n",
    "    'double': 'double',\n",
    "    'hit_by_pitch': 'hit_by_pitch',\n",
    "    'home_run': 'home_run',\n",
    "    'grounded_into_double_play': 'field_out',\n",
    "    'fielders_choice_out': 'field_out',\n",
    "    'fielders_choice': 'field_out',\n",
    "    'field_error': None,\n",
    "    'double_play': 'field_out',\n",
    "    'sac_fly': 'field_out',\n",
    "    'strikeout_double_play': None,\n",
    "    'triple': 'triple',\n",
    "    'caught_stealing_2b': None,\n",
    "    'sac_bunt': 'field_out',\n",
    "    'catcher_interf': None,\n",
    "    'caught_stealing_3b': None,\n",
    "    'sac_fly_double_play': 'field_out',\n",
    "    'triple_play': 'field_out',\n",
    "    'other_out': 'field_out',\n",
    "    'pickoff_3b': None,\n",
    "    'caught_stealing_home': None,\n",
    "    'pickoff_1b': None,\n",
    "    'pickoff_2b': None,\n",
    "    'wild_pitch': None,\n",
    "    'stolen_base_2b': None,\n",
    "    'pickoff_caught_stealing_3b': None,\n",
    "    'pickoff_caught_stealing_2b': None,\n",
    "    'sac_bunt_double_play': None,\n",
    "    'passed_ball': None,\n",
    "    'pickoff_caught_stealing_home': None\n",
    "}\n",
    "\n",
    "# Join the run values data with the main dataframe based on event type, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['event_type', 'balls', 'strikes'],\n",
    "             right_on=['event', 'balls', 'strikes'], \n",
    "             how='left')\n",
    "\n",
    "# Replace play descriptions with the grouped outcomes from des_dict\n",
    "df = df.with_columns(pl.col(\"play_description\").replace_strict(des_dict, default=None))\n",
    "\n",
    "# Join the run values data again based on the play description, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['play_description', 'balls', 'strikes'],\n",
    "             right_on=['event', 'balls', 'strikes'], \n",
    "             how='left',\n",
    "             suffix='_des')\n",
    "\n",
    "# # Adjust delta_run_exp for whiffs by applying a multiplier (e.g., 1.5x for whiffs)\n",
    "# df = df.with_columns(\n",
    "#     pl.when(pl.col(\"play_description\") == \"swinging_strike\")  # Focus on whiffs\n",
    "#     .then(pl.col(\"delta_run_exp\") * 1.5)  # Increase weight for whiffs\n",
    "#     .otherwise(pl.col(\"delta_run_exp\"))\n",
    "#     .alias(\"delta_run_exp_adjusted\")\n",
    "# )\n",
    "# df = df.with_columns(\n",
    "#     pl.when(pl.col(\"play_description\") == \"strikeout\")  # Focus on whiffs\n",
    "#     .then(pl.col(\"delta_run_exp\") * 1.5)  # Increase weight for whiffs\n",
    "#     .otherwise(pl.col(\"delta_run_exp\"))\n",
    "#     .alias(\"delta_run_exp_adjusted\")\n",
    "# )\n",
    "# Assign the target column based on the adjusted delta run expectation\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"delta_run_exp_adjusted\").is_null())\n",
    "    .then(pl.col(\"delta_run_exp_des\"))\n",
    "    .otherwise(pl.col(\"delta_run_exp_adjusted\"))\n",
    "    .alias(\"target\")\n",
    ")\n",
    "\n",
    "# The resulting 'target' column now has adjusted run values for whiffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the run values data from CSV\n",
    "df_run_values = pl.read_csv(\"adj_run_values2.csv\")  \n",
    "\n",
    "# Define a dictionary to group pitch outcomes together\n",
    "des_dict = {\n",
    "    'Ball': 'ball',\n",
    "    'In play, run(s)': 'hit_into_play',\n",
    "    'In play, out(s)': 'hit_into_play',\n",
    "    'In play, no out': 'hit_into_play',\n",
    "    'Called Strike': 'called_strike',\n",
    "    'Foul': 'foul',\n",
    "    'Swinging Strike': 'swinging_strike',\n",
    "    'Blocked Ball': 'ball',\n",
    "    'Swinging Strike (Blocked)': 'swinging_strike',\n",
    "    'Foul Tip': 'swinging_strike',\n",
    "    'Foul Bunt': 'foul',\n",
    "    'Hit By Pitch': 'hit_by_pitch',\n",
    "    'Pitchout': 'ball',\n",
    "    'Missed Bunt': 'swinging_strike',\n",
    "    'Bunt Foul Tip': 'swinging_strike',\n",
    "    'Foul Pitchout': 'foul',\n",
    "    'Ball In Dirt': 'ball'\n",
    "}\n",
    "\n",
    "# Define a dictionary to group events together\n",
    "event_dict = {\n",
    "    'game_advisory': None,\n",
    "    'single': 'single',\n",
    "    'walk': 'walk',\n",
    "    np.nan: None,\n",
    "    'strikeout': 'strikeout',\n",
    "    'field_out': 'field_out',\n",
    "    'force_out': 'field_out',\n",
    "    'double': 'double',\n",
    "    'hit_by_pitch': 'hit_by_pitch',\n",
    "    'home_run': 'home_run',\n",
    "    'grounded_into_double_play': 'field_out',\n",
    "    'fielders_choice_out': 'field_out',\n",
    "    'fielders_choice': 'field_out',\n",
    "    'field_error': None,\n",
    "    'double_play': 'field_out',\n",
    "    'sac_fly': 'field_out',\n",
    "    'strikeout_double_play': None,\n",
    "    'triple': 'triple',\n",
    "    'caught_stealing_2b': None,\n",
    "    'sac_bunt': 'field_out',\n",
    "    'catcher_interf': None,\n",
    "    'caught_stealing_3b': None,\n",
    "    'sac_fly_double_play': 'field_out',\n",
    "    'triple_play': 'field_out',\n",
    "    'other_out': 'field_out',\n",
    "    'pickoff_3b': None,\n",
    "    'caught_stealing_home': None,\n",
    "    'pickoff_1b': None,\n",
    "    'pickoff_2b': None,\n",
    "    'wild_pitch': None,\n",
    "    'stolen_base_2b': None,\n",
    "    'pickoff_caught_stealing_3b': None,\n",
    "    'pickoff_caught_stealing_2b': None,\n",
    "    'sac_bunt_double_play': None,\n",
    "    'passed_ball': None,\n",
    "    'pickoff_caught_stealing_home': None\n",
    "}\n",
    "\n",
    "# Join the run values data with the main dataframe based on event type, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['event_type', 'balls', 'strikes'],\n",
    "             right_on=['event', 'balls', 'strikes'], \n",
    "             how='left')\n",
    "\n",
    "# Replace play descriptions with the grouped outcomes from des_dict\n",
    "df = df.with_columns(pl.col(\"play_description\").replace_strict(des_dict, default=None))\n",
    "\n",
    "# Join the run values data again based on the play description, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['play_description', 'balls', 'strikes'],\n",
    "             right_on=['event', 'balls', 'strikes'], \n",
    "             how='left',\n",
    "             suffix='_des')\n",
    "\n",
    "# Assign the target column based on the delta run expectation\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"delta_run_exp\").is_null())\n",
    "    .then(pl.col(\"delta_run_exp_des\"))\n",
    "    .otherwise(pl.col(\"delta_run_exp\"))\n",
    "    .alias(\"target\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the run values data from CSV\n",
    "df_run_values = pl.read_csv(\"adj_run_values.csv\")  \n",
    "\n",
    "# Define a dictionary to group pitch outcomes together\n",
    "des_dict = {\n",
    "    'Ball': 'ball',\n",
    "    'In play, run(s)': 'hit_into_play',\n",
    "    'In play, out(s)': 'hit_into_play',\n",
    "    'In play, no out': 'hit_into_play',\n",
    "    'Called Strike': 'called_strike',\n",
    "    'Foul': 'foul',\n",
    "    'Swinging Strike': 'swinging_strike',\n",
    "    'Blocked Ball': 'ball',\n",
    "    'Swinging Strike (Blocked)': 'swinging_strike',\n",
    "    'Foul Tip': 'swinging_strike',\n",
    "    'Foul Bunt': 'foul',\n",
    "    'Hit By Pitch': 'hit_by_pitch',\n",
    "    'Pitchout': 'ball',\n",
    "    'Missed Bunt': 'swinging_strike',\n",
    "    'Bunt Foul Tip': 'swinging_strike',\n",
    "    'Foul Pitchout': 'foul',\n",
    "    'Ball In Dirt': 'ball'\n",
    "}\n",
    "\n",
    "# Define a dictionary to group events together\n",
    "event_dict = {\n",
    "    'game_advisory': None,\n",
    "    'single': 'single',\n",
    "    'walk': 'walk',\n",
    "    np.nan: None,\n",
    "    'strikeout': 'strikeout',\n",
    "    'field_out': 'field_out',\n",
    "    'force_out': 'field_out',\n",
    "    'double': 'double',\n",
    "    'hit_by_pitch': 'hit_by_pitch',\n",
    "    'home_run': 'home_run',\n",
    "    'grounded_into_double_play': 'field_out',\n",
    "    'fielders_choice_out': 'field_out',\n",
    "    'fielders_choice': 'field_out',\n",
    "    'field_error': None,\n",
    "    'double_play': 'field_out',\n",
    "    'sac_fly': 'field_out',\n",
    "    'strikeout_double_play': None,\n",
    "    'triple': 'triple',\n",
    "    'caught_stealing_2b': None,\n",
    "    'sac_bunt': 'field_out',\n",
    "    'catcher_interf': None,\n",
    "    'caught_stealing_3b': None,\n",
    "    'sac_fly_double_play': 'field_out',\n",
    "    'triple_play': 'field_out',\n",
    "    'other_out': 'field_out',\n",
    "    'pickoff_3b': None,\n",
    "    'caught_stealing_home': None,\n",
    "    'pickoff_1b': None,\n",
    "    'pickoff_2b': None,\n",
    "    'wild_pitch': None,\n",
    "    'stolen_base_2b': None,\n",
    "    'pickoff_caught_stealing_3b': None,\n",
    "    'pickoff_caught_stealing_2b': None,\n",
    "    'sac_bunt_double_play': None,\n",
    "    'passed_ball': None,\n",
    "    'pickoff_caught_stealing_home': None\n",
    "}\n",
    "\n",
    "# Join the run values data with the main dataframe based on event type, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['event_type', 'balls', 'strikes', 'pitcher_hand', 'batter_hand'],\n",
    "             right_on=['event', 'balls', 'strikes', 'pitcher_hand', 'batter_hand'], \n",
    "             how='left')\n",
    "\n",
    "# Replace play descriptions with the grouped outcomes from des_dict\n",
    "df = df.with_columns(pl.col(\"play_description\").replace_strict(des_dict, default=None))\n",
    "\n",
    "# Join the run values data again based on the play description, balls, and strikes\n",
    "df = df.join(df_run_values, \n",
    "             left_on=['play_description', 'balls', 'strikes', 'pitcher_hand', 'batter_hand'],\n",
    "             right_on=['event', 'balls', 'strikes', 'pitcher_hand', 'batter_hand'], \n",
    "             how='left',\n",
    "             suffix='_des')\n",
    "\n",
    "# Assign the target column based on the delta run expectation\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"delta_run_exp\").is_null())\n",
    "    .then(pl.col(\"delta_run_exp_des\"))\n",
    "    .otherwise(pl.col(\"delta_run_exp\"))\n",
    "    .alias(\"target\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "As part of modelling, I engineered features to help improve performance. This included mirroring horizontal break and horizontal release points for Left-Handed Pitchers as well as including the features which relate to each pitcher's primary Fastball.\n",
    "\n",
    "The following function returns the engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Extract the year from the game_date column\n",
    "    df = df.with_columns(\n",
    "        pl.col('game_date').str.slice(0, 4).alias('year')\n",
    "    )\n",
    "\n",
    "    # Mirror horizontal break for left-handed pitchers\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('pitcher_hand') == 'L')\n",
    "        .then(-pl.col('ax'))\n",
    "        .otherwise(pl.col('ax'))\n",
    "        .alias('ax')\n",
    "    )\n",
    "\n",
    "    # Mirror horizontal release point for left-handed pitchers\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('pitcher_hand') == 'L')\n",
    "        .then(pl.col('x0'))\n",
    "        .otherwise(-pl.col('x0'))\n",
    "        .alias('x0')\n",
    "    )\n",
    "\n",
    "    # Define the pitch types to be considered\n",
    "    pitch_types = ['SI', 'FF', 'FC']\n",
    "\n",
    "    # Filter the DataFrame to include only the specified pitch types\n",
    "    df_filtered = df.filter(pl.col('pitch_type').is_in(pitch_types))\n",
    "\n",
    "    # Group by pitcher_id and year, then aggregate to calculate average speed and usage percentage\n",
    "    df_agg = df_filtered.group_by(['pitcher_id', 'year', 'pitch_type']).agg([\n",
    "        pl.col('start_speed').mean().alias('avg_fastball_speed'),\n",
    "        pl.col('az').mean().alias('avg_fastball_az'),\n",
    "        pl.col('ax').mean().alias('avg_fastball_ax'),\n",
    "        pl.len().alias('count')\n",
    "    ])\n",
    "\n",
    "    # Sort the aggregated data by count and average fastball speed\n",
    "    df_agg = df_agg.sort(['count', 'avg_fastball_speed'], descending=[True, True])\n",
    "    df_agg = df_agg.unique(subset=['pitcher_id', 'year'], keep='first')\n",
    "\n",
    "    # Join the aggregated data with the main DataFrame\n",
    "    df = df.join(df_agg, on=['pitcher_id', 'year'])\n",
    "\n",
    "    # If no fastball, use the fastest pitch for avg_fastball_speed\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('avg_fastball_speed').is_null())\n",
    "        .then(pl.col('start_speed').max().over('pitcher_id'))\n",
    "        .otherwise(pl.col('avg_fastball_speed'))\n",
    "        .alias('avg_fastball_speed')\n",
    "    )\n",
    "\n",
    "    # If no fastball, use the fastest pitch for avg_fastball_az\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('avg_fastball_az').is_null())\n",
    "        .then(pl.col('az').max().over('pitcher_id'))\n",
    "        .otherwise(pl.col('avg_fastball_az'))\n",
    "        .alias('avg_fastball_az')\n",
    "    )\n",
    "\n",
    "    # If no fastball, use the fastest pitch for avg_fastball_ax\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('avg_fastball_ax').is_null())\n",
    "        .then(pl.col('ax').max().over('ax'))\n",
    "        .otherwise(pl.col('avg_fastball_ax'))\n",
    "        .alias('avg_fastball_ax')\n",
    "    )\n",
    "\n",
    "    # Calculate pitch differentials\n",
    "    df = df.with_columns(\n",
    "        (pl.col('start_speed') - pl.col('avg_fastball_speed')).alias('speed_diff'),\n",
    "        (pl.col('az') - pl.col('avg_fastball_az')).alias('az_diff'),\n",
    "        (pl.col('ax') - pl.col('avg_fastball_ax')).abs().alias('ax_diff')\n",
    "    )\n",
    "\n",
    "    # Cast the year column to integer type\n",
    "    df = df.with_columns(\n",
    "        pl.col('year').cast(pl.Int64)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "df = feature_engineering(df.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As outlined in my Medium Article, I will be training on 2020-22 Data. I will then validate the model's predictiveness using 2023 data and comparing it to 2024 results. After I validate that the model is effectively predicting future performance, I will train with 2023 data and then test its predictiveness using 2024 data and comparing it to 2024 results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the years 2020, 2021, and 2022\n",
    "df_train = df.filter(pl.col('year').is_in([2020, 2021, 2022]))\n",
    "\n",
    "# Define the features to be used for training\n",
    "features = ['start_speed',\n",
    "            'spin_rate',\n",
    "            'extension',\n",
    "            'az',\n",
    "            'ax',\n",
    "            'x0',\n",
    "            'z0',\n",
    "            'speed_diff',\n",
    "            'az_diff',\n",
    "            'ax_diff']\n",
    "\n",
    "# Define the target variable\n",
    "target = 'target'\n",
    "\n",
    "# Drop rows with null values in the specified features and target column\n",
    "df_train = df_train.drop_nulls(subset=features + [target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "I used an LGBMRegressor for the model. I also applied a RobustScaler to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Extract features and target from the training dataframe\n",
    "X = df_train[features]\n",
    "y = df_train['target']\n",
    "\n",
    "# Create a pipeline with RobustScaler and LGBMRegressor\n",
    "model = make_pipeline(\n",
    "    RobustScaler(),            # Robust Scaler to scale the features\n",
    "    LGBMRegressor(\n",
    "        n_estimators=1000,         # Number of boosting rounds (trees) to be built.\n",
    "        learning_rate=0.01,        # Step size shrinkage used to prevent overfitting. Smaller values require more boosting rounds.\n",
    "        num_leaves=31,             # Maximum number of leaves in one tree. Controls the complexity of the model.\n",
    "        max_depth=-1,              # Maximum depth of the tree. -1 means no limit.\n",
    "        min_child_samples=20,      # Minimum number of data points required in a leaf. Helps control overfitting.\n",
    "        subsample=0.8,             # Fraction of data to be used for each boosting round. Helps prevent overfitting.\n",
    "        colsample_bytree=0.8,      # Fraction of features to be used for each boosting round. Helps prevent overfitting.\n",
    "        reg_alpha=0.1,             # L1 regularization term on weights. Helps prevent overfitting.\n",
    "        reg_lambda=0.2,            # L2 regularization term on weights. Helps prevent overfitting.\n",
    "        random_state=42,           # Seed for reproducibility.\n",
    "        force_row_wise=True        # Force row-wise (data parallel) computation. Useful for handling large datasets.\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Save the model to a file\n",
    "import joblib\n",
    "joblib.dump(model, 'model/stuff_modelv2.joblib')\n",
    "print(\"Model saved to model/lgbm_model_2020_2022.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "LGBMRegressor returns feature importance which helps us understand which features are most influential in making predictions. From our trained model, we see that Pitch Velocity and iVB are the most impactful features, which is intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "lgbm_model = model.named_steps['lgbmregressor']\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = lgbm_model.feature_importances_\n",
    "\n",
    "# Assuming 'features' is a list of feature names\n",
    "importance_df = pl.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort(by='Importance', descending=True)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "To validate the model, we wil predicting tjStuff+ values on 2023 data and then calculating the correlation of tjStuff+ to 2024 results. The results we will use are FIP, wOBA, and K-BB%. We will also calculate tjStuff+ on 2024 data to evaluate the 'stickiness' of the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the rows for the year 2023 and drop rows with null values in the specified features and target column\n",
    "df_test = df.filter(pl.col('year').is_in([2023, 2024])).drop_nulls(subset=features + [target])\n",
    "\n",
    "# Predict the target values for the 2023 data using the trained model\n",
    "df_test = df_test.with_columns(\n",
    "    pl.Series(name=\"target\", values=model.predict(df_test[features].to_numpy()))\n",
    ")\n",
    "\n",
    "# For help with plotting the pitch data, we will use the following dictionary to map pitch types to their corresponding colours\n",
    "### PITCH COLOURS ###\n",
    "pitch_colours = {\n",
    "    ## Fastballs ##\n",
    "    'FF': {'colour': '#FF0000', 'name': '4-Seam Fastball'},\n",
    "    'FA': {'colour': '#FF0000', 'name': 'Fastball'},\n",
    "    'SI': {'colour': '#623fff', 'name': 'Sinker'},\n",
    "    'FC': {'colour': '#FF007D', 'name': 'Cutter'},\n",
    "\n",
    "    ## Offspeed ##\n",
    "    'CH': {'colour': '#FFB000', 'name': 'Changeup'},\n",
    "    'FS': {'colour': '#FE6100', 'name': 'Splitter'},\n",
    "    'SC': {'colour': '#F08223', 'name': 'Screwball'},\n",
    "    'FO': {'colour': '#FFEB00', 'name': 'Forkball'},\n",
    "\n",
    "    ## Sliders ##\n",
    "    'SL': {'colour': '#67E18D', 'name': 'Slider'},\n",
    "    'ST': {'colour': '#8e44ad', 'name': 'Sweeper'},\n",
    "    'SV': {'colour': '#00d7e1', 'name': 'Slurve'},\n",
    "\n",
    "    ## Curveballs ##\n",
    "    'KC': {'colour': '#648FFF', 'name': 'Knuckle Curve'},\n",
    "    'CU': {'colour': '#274BFC', 'name': 'Curveball'},\n",
    "    'CS': {'colour': '#3025CE', 'name': 'Slow Curve'},\n",
    "    'EP': {'colour': '#C2C2C2', 'name': 'Eephus'},\n",
    "\n",
    "    ## Others ##\n",
    "    'KN': {'colour': '#867A08', 'name': 'Knuckleball'},\n",
    "    'PO': {'colour': '#472C30', 'name': 'Pitch Out'},\n",
    "    'UN': {'colour': '#9C8975', 'name': 'Unknown'},\n",
    "}\n",
    "\n",
    "# Create a dictionary mapping pitch types to their colors\n",
    "dict_colour = dict(zip(pitch_colours.keys(), [pitch_colours[key]['colour'] for key in pitch_colours]))\n",
    "\n",
    "# Create a dictionary mapping pitch types to their colors\n",
    "dict_pitch = dict(zip(pitch_colours.keys(), [pitch_colours[key]['name'] for key in pitch_colours]))\n",
    "\n",
    "# Create a dictionary mapping pitch types to their colors\n",
    "dict_pitch_desc_type = dict(zip([pitch_colours[key]['name'] for key in pitch_colours],pitch_colours.keys()))\n",
    "\n",
    "\n",
    "# Create a dictionary mapping pitch types to their colors\n",
    "dict_pitch_name = dict(zip([pitch_colours[key]['name'] for key in pitch_colours], \n",
    "                           [pitch_colours[key]['colour'] for key in pitch_colours]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tjStuff+ is normally distributed and can be calculated using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the rows for the year 2023 and 2024\n",
    "df_2023 = df_test.filter(pl.col('year') == 2023)\n",
    "df_2024 = df_test.filter(pl.col('year') == 2024)\n",
    "\n",
    "## 2023 tjStuff+ ##\n",
    "# Calculate the mean and standard deviation of the target column for 2023\n",
    "target_mean = df_2023['target'].mean()\n",
    "target_std = df_2023['target'].std()\n",
    "\n",
    "# Standardize the target column to create a z-score for 2023\n",
    "df_2023 = df_2023.with_columns(\n",
    "    ((pl.col('target') - target_mean) / target_std).alias('target_zscore')\n",
    ")\n",
    "\n",
    "# Convert the z-score to tj_stuff_plus for 2023\n",
    "df_2023 = df_2023.with_columns(\n",
    "    (100 - (pl.col('target_zscore') * 10)).alias('tj_stuff_plus')\n",
    ")\n",
    "\n",
    "# Aggregate tj_stuff_plus by pitcher_id and year for 2023\n",
    "df_agg_2023 = df_2023.group_by(['pitcher_id', 'year']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('count'),\n",
    "    pl.col('tj_stuff_plus').mean()\n",
    ")\n",
    "\n",
    "## 2024 tjStuff+ ##\n",
    "# Standardize the target column to create a z-score for 2024 using 2023 mean and std\n",
    "df_2024 = df_2024.with_columns(\n",
    "    ((pl.col('target') - target_mean) / target_std).alias('target_zscore')\n",
    ")\n",
    "\n",
    "# Convert the z-score to tj_stuff_plus for 2024\n",
    "df_2024 = df_2024.with_columns(\n",
    "    (100 - (pl.col('target_zscore') * 10)).alias('tj_stuff_plus')\n",
    ")\n",
    "\n",
    "# Aggregate tj_stuff_plus by pitcher_id and year for 2024\n",
    "df_agg_2024 = df_2024.group_by(['pitcher_id', 'year']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('count'),\n",
    "    pl.col('tj_stuff_plus').mean()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calculates tjStuff+ and plots the Histogram of 2023 pitch level tjStuff+. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert Polars DataFrame to Pandas DataFrame for Seaborn compatibility\n",
    "df_2023_pd = df_2023.to_pandas()\n",
    "\n",
    "# Create subplots for the histograms\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot the histogram of tj_stuff_plus for specific pitch types\n",
    "sns.histplot(data=df_2023_pd[df_2023_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "             x='tj_stuff_plus', \n",
    "             binrange=[60, 140], \n",
    "             bins=40,\n",
    "             ax=ax[0]\n",
    "             )\n",
    "\n",
    "# Set the title of the first subplot\n",
    "ax[0].set_title('2023 Pitch Stuff+ Distribution')\n",
    "\n",
    "# Plot the histogram of tj_stuff_plus for specific pitch types, colored by pitch type\n",
    "sns.histplot(data=df_2023_pd[df_2023_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "             x='tj_stuff_plus', \n",
    "             binrange=[60, 140], \n",
    "             bins=40,\n",
    "             hue='pitch_type',\n",
    "             multiple='stack',  \n",
    "             palette=dict_colour,\n",
    "             ax=ax[1]\n",
    "             )\n",
    "\n",
    "# Set the title of the second subplot\n",
    "ax[1].set_title('2023 Pitch Stuff+ Distribution by Pitch Type')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax[0].set_xlabel('Stuff+')\n",
    "ax[1].set_xlabel('Stuff+')\n",
    "\n",
    "# Change the legend title to 'Pitch Type'\n",
    "ax[1].get_legend().set_title(\"Pitch Type\")   \n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the median of tj_stuff_plus for each pitch_type\n",
    "mean_values = df_2023_pd[df_2023_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', \n",
    "                                                        'CH', 'FS', 'CU', 'KC'])].groupby('pitch_type')['tj_stuff_plus'].median().sort_values(ascending=False)\n",
    "\n",
    "# Map the median values to the dataframe\n",
    "df_2023_pd['tj_stuff_plus_mean'] = df_2023_pd['pitch_type'].map(mean_values.to_dict())\n",
    "\n",
    "# Sort the dataframe by the median values of tj_stuff_plus\n",
    "df_2023_pd = df_2023_pd.sort_values(by='tj_stuff_plus_mean', ascending=False)\n",
    "\n",
    "# Create a subplot for the boxen plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot the boxen plot of tj_stuff_plus for specific pitch types, colored by pitch type\n",
    "bp = sns.boxenplot(data=df_2023_pd[df_2023_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "               x='tj_stuff_plus', \n",
    "               y='pitch_type',\n",
    "               palette=dict_colour,\n",
    "               ax=ax,\n",
    "               showfliers=False,  # Do not show outliers\n",
    "               k_depth=6          # Number of boxes to draw\n",
    "               )\n",
    "\n",
    "bp.set_yticklabels([dict_pitch[x.get_text()] + f' ({x.get_text()})' for x in bp.get_yticklabels()])\n",
    "\n",
    "# Annotate the median values on the plot\n",
    "for index, row in mean_values.reset_index().iterrows():\n",
    "    ax.text(row['tj_stuff_plus'], \n",
    "            index, \n",
    "            f'{row[\"tj_stuff_plus\"]:.0f}', \n",
    "            color='black', \n",
    "            ha=\"center\", \n",
    "            va=\"center\",\n",
    "            bbox=dict(facecolor='white', alpha=1,edgecolor='k')  # White background for the text\n",
    "            )\n",
    "\n",
    "\n",
    "# Set the x-axis limits\n",
    "ax.set_xlim(60, 140)\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('2023 tjStuff+ Distribution and Median by Pitch Type')\n",
    "\n",
    "# Set the x-axis and y-axis label\n",
    "ax.set_xlabel('tjStuff+')\n",
    "ax.set_ylabel('Pitch Type')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the Fangraphs API, we can easily grab 2024 MLB Pitcher Results. I also downloaded Pitching wOBA data from Baseball Savant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch data from Fangraphs API for the 2023 and 2024 MLB seasons\n",
    "data = requests.get(\"https://www.fangraphs.com/api/leaders/major-league/data?age=&pos=all&stats=pit&lg=all&season=2024&season1=2023&ind=1&qual=0&type=8&month=0&pageitems=500000\").json()\n",
    "\n",
    "# Define the schema explicitly for the incoming data\n",
    "schema = {\n",
    "    'playerid': pl.Int64,\n",
    "    'xMLBAMID': pl.Int64,\n",
    "    'PlayerName': pl.Utf8,\n",
    "    'Season': pl.Int64,\n",
    "    'Team': pl.Utf8,\n",
    "    'G': pl.Int64,\n",
    "    'IP': pl.Float64,\n",
    "    'K-BB%': pl.Float64,\n",
    "    'ERA': pl.Float64,\n",
    "    'FIP': pl.Float64,\n",
    "    'xFIP': pl.Float64,\n",
    "    'TBF': pl.Int64,\n",
    "    'Pitches': pl.Int64,\n",
    "}\n",
    "\n",
    "# Create a Polars DataFrame from the fetched data\n",
    "df_fg = pl.DataFrame(data=data['data'], schema=schema)\n",
    "\n",
    "# Add a column for the previous year (Season - 1)\n",
    "df_fg = df_fg.with_columns((pl.col('Season') - 1).alias('year_n1'))\n",
    "\n",
    "# Load wOBA data from a CSV file\n",
    "df_woba = pl.read_csv('woba_2020_2024.csv')\n",
    "\n",
    "# Join the Fangraphs data with the wOBA data on player ID and season\n",
    "df_fg = df_fg.join(df_woba, left_on=['xMLBAMID', 'Season'], right_on=['player_id', 'year'], how='left')\n",
    "\n",
    "# Join the Fangraphs data with itself to get the previous season's data\n",
    "df_join = df_fg.join(df_fg, left_on=['xMLBAMID', 'year_n1'], right_on=['xMLBAMID', 'Season'], how='inner', suffix='_2023')\n",
    "\n",
    "\n",
    "# Join the resulting DataFrame with the aggregated data to get tj_stuff_plus\n",
    "df_join = df_join.join(df_agg_2024, left_on=['xMLBAMID', 'Season'], right_on=['pitcher_id', 'year'], how='inner').sort('tj_stuff_plus', descending=True)\n",
    "\n",
    "\n",
    "# Join the resulting DataFrame with the aggregated data to get tj_stuff_plus\n",
    "df_join = df_join.join(df_agg_2023, left_on=['xMLBAMID', 'year_n1'], right_on=['pitcher_id', 'year'], how='inner',suffix='_2023').sort('tj_stuff_plus', descending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the 2023 and 2024 Data loaded into a DataFrame, we can calculate correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the minimum number of pitches required for filtering\n",
    "min_pitches = 100\n",
    "\n",
    "# Filter the DataFrame to include only rows where the count and Pitches are greater than or equal to min_pitches\n",
    "df_join_filter = df_join.filter(\n",
    "    (pl.col('count') >= min_pitches) & (pl.col('Pitches') >= min_pitches)\n",
    ")\n",
    "\n",
    "# Print the minimum pitches, sample size, and average pitches\n",
    "print('Minimum Pitches:', min_pitches)\n",
    "print('Sample Size:', len(df_join_filter))\n",
    "print('Average Pitches:', int(df_join_filter['Pitches'].mean()))\n",
    "\n",
    "# Calculate and print the correlation between 2023 and 2024 metrics\n",
    "print('Correlation between 2023 and 2024:')\n",
    "corr_df = df_join_filter.to_pandas()[[\n",
    "    'tj_stuff_plus_2023', 'tj_stuff_plus', 'FIP', 'woba', 'K-BB%',\n",
    "    'FIP_2023', 'woba_2023', 'K-BB%_2023'\n",
    "]].corr()[[\n",
    "    'FIP', 'woba', 'K-BB%', 'tj_stuff_plus'\n",
    "]].loc[\n",
    "    ['tj_stuff_plus_2023', 'FIP_2023', 'woba_2023', 'K-BB%_2023']\n",
    "].abs().round(2)\n",
    "\n",
    "# Rename the index and columns for better readability\n",
    "corr_df.index = ['2023 tjStuff+', '2023 FIP', '2023 wOBA', '2023 K-BB%']\n",
    "corr_df.columns = ['2024 FIP', '2024 wOBA', '2024 K-BB%', '2024 tjStuff+']\n",
    "\n",
    "# Display the correlation DataFrame\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am content with how the model is performing on a predictive level. To evaluate the model on a descriptive level, I will retrain the model using 2020-23 data, and then test on 2024 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# Filter the dataframe to include only the years 2020, 2021, 2022, and 2023\n",
    "df_train = df.filter(pl.col('year').is_in([2020, 2021, 2022,2023]))\n",
    "\n",
    "# Define the features to be used for training\n",
    "features = ['start_speed',\n",
    "            'spin_rate',\n",
    "            'extension',\n",
    "            'az',\n",
    "            'ax',\n",
    "            'x0',\n",
    "            'z0',\n",
    "            'speed_diff',\n",
    "            'az_diff',\n",
    "            'ax_diff']\n",
    "\n",
    "# Define the target variable\n",
    "target = 'target'\n",
    "\n",
    "# Drop rows with null values in the specified features and target column\n",
    "df_train = df_train.drop_nulls(subset=features + [target])\n",
    "\n",
    "# Extract features and target from the training dataframe\n",
    "X = df_train[features]\n",
    "y = df_train['target']\n",
    "\n",
    "# Create a pipeline with RobustScaler and LGBMRegressor\n",
    "model = make_pipeline(\n",
    "    RobustScaler(),            # Robust Scaler to scale the features\n",
    "    LGBMRegressor(\n",
    "        n_estimators=1000,         # Number of boosting rounds (trees) to be built.\n",
    "        learning_rate=0.01,        # Step size shrinkage used to prevent overfitting. Smaller values require more boosting rounds.\n",
    "        num_leaves=31,             # Maximum number of leaves in one tree. Controls the complexity of the model.\n",
    "        max_depth=-1,              # Maximum depth of the tree. -1 means no limit.\n",
    "        min_child_samples=20,      # Minimum number of data points required in a leaf. Helps control overfitting.\n",
    "        subsample=0.8,             # Fraction of data to be used for each boosting round. Helps prevent overfitting.\n",
    "        colsample_bytree=0.8,      # Fraction of features to be used for each boosting round. Helps prevent overfitting.\n",
    "        reg_alpha=0.1,             # L1 regularization term on weights. Helps prevent overfitting.\n",
    "        reg_lambda=0.2,            # L2 regularization term on weights. Helps prevent overfitting.\n",
    "        random_state=42,           # Seed for reproducibility.\n",
    "        force_row_wise=True        # Force row-wise (data parallel) computation. Useful for handling large datasets.\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Save the model to a file\n",
    "# import joblib\n",
    "# joblib.dump(model, 'model/lgbm_model_2020_2023.joblib')\n",
    "# print(\"Model saved to model/lgbm_model_2020_2023.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate tjStuff+ again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the rows for the year 2024 and drop rows with null values in the specified features and target column\n",
    "df_test = df.filter(pl.col('year').is_in([2024])).drop_nulls(subset=features + [target])\n",
    "\n",
    "# Predict the target values for the 2024 data using the trained model\n",
    "df_test = df_test.with_columns(\n",
    "    pl.Series(name=\"target\", values=model.predict(df_test[features].to_numpy()))\n",
    ")\n",
    "\n",
    "# Filter the dataframe to include only the rows for the year 2024\n",
    "df_2024 = df_test.filter(pl.col('year') == 2024)\n",
    "\n",
    "## 2024 tjStuff+ ##\n",
    "# Calculate the mean and standard deviation of the target column\n",
    "target_mean = df_2024['target'].mean()\n",
    "target_std = df_2024['target'].std()\n",
    "\n",
    "# Print the mean and standard deviation of the target column\n",
    "print('Mean xRV/100:', round(target_mean * 100, 2))\n",
    "print('StDev xRV/100:', round(target_std * 100, 2))\n",
    "\n",
    "# Standardize the target column to create a z-score\n",
    "df_2024 = df_2024.with_columns(\n",
    "    ((pl.col('target') - target_mean) / target_std).alias('target_zscore')\n",
    ")\n",
    "\n",
    "# Convert the z-score to tj_stuff_plus\n",
    "df_2024 = df_2024.with_columns(\n",
    "    (100 - (pl.col('target_zscore') * 10)).alias('tj_stuff_plus')\n",
    ")\n",
    "\n",
    "# Aggregate tj_stuff_plus by pitcher_id and year\n",
    "df_agg_2024 = df_2024.group_by(['pitcher_id', 'year']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('count'),\n",
    "    pl.col('tj_stuff_plus').mean()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot its pitch level distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert Polars DataFrame to Pandas DataFrame for Seaborn compatibility\n",
    "df_2024_pd = df_2024.to_pandas()\n",
    "\n",
    "# Create subplots for the histograms\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot the histogram of tj_stuff_plus for specific pitch types\n",
    "sns.histplot(data=df_2024_pd[df_2024_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "             x='tj_stuff_plus', \n",
    "             binrange=[60, 140], \n",
    "             bins=40,\n",
    "             ax=ax[0]\n",
    "             )\n",
    "\n",
    "# Set the title of the first subplot\n",
    "ax[0].set_title('2024 Pitch Stuff+ Distribution')\n",
    "\n",
    "# Plot the histogram of tj_stuff_plus for specific pitch types, colored by pitch type\n",
    "sns.histplot(data=df_2024_pd[df_2024_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "             x='tj_stuff_plus',\n",
    "             palette=dict_colour,\n",
    "             binrange=[60, 140], \n",
    "             bins=40,\n",
    "             hue='pitch_type',\n",
    "             multiple='stack',  \n",
    "             ax=ax[1]\n",
    "             )\n",
    "\n",
    "# Set the title of the second subplot\n",
    "ax[1].set_title('2024 Pitch Stuff+ Distribution by Pitch Type')\n",
    "\n",
    "\n",
    "# Set the x-axis label\n",
    "ax[0].set_xlabel('tjStuff+')\n",
    "ax[1].set_xlabel('tjStuff+')\n",
    "\n",
    "# Change the legend title to 'Pitch Type'\n",
    "ax[1].get_legend().set_title(\"Pitch Type\")   \n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now well make a leaderboard of the top 10 pitchers by tj_stuff_plus\n",
    "df_leaderboard = df_agg_2024.sort('tj_stuff_plus', descending=True).head(10)\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('tj_stuff_plus').round(2).alias('tj_stuff_plus')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').cast(pl.Utf8).alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('xMLBAMID_', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2024', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2023', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2022', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2021', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2020', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2023_2024', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2024_2023', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2024_2024', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2023_2023', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2022_2022', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2021_2021', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2020_2020', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2020_2021', '').alias('pitcher_id')\n",
    ")\n",
    "df_leaderboard = df_leaderboard.with_columns(\n",
    "    pl.col('pitcher_id').str.replace('_2020_2022', '').alias('pitcher_id')\n",
    ")\n",
    "#now show the leaderboard\n",
    "plt.show(df_leaderboard.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot its Pitch Type distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the mean of tj_stuff_plus for each pitch_type\n",
    "df_2024_pd_group = df_2024_pd.groupby('pitch_type')['tj_stuff_plus'].agg(\n",
    "    mean='mean',\n",
    "    std='std',\n",
    "    median='median',\n",
    "    min='min',\n",
    "    max='max',\n",
    "    percentile_2=lambda x: x.quantile(0.025),\n",
    "    percentile_98=lambda x: x.quantile(0.975)\n",
    ").sort_values('mean', ascending=False).reset_index()\n",
    "df_2024_pd_group.to_csv('tj_stuff_plus_pitch.csv', index=False, header=True)\n",
    "\n",
    "# Calculate the median of tj_stuff_plus for each pitch_type\n",
    "median_values = df_2024_pd[df_2024_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', \n",
    "                                                        'CH', 'FS', 'CU', 'KC'])].groupby('pitch_type')['tj_stuff_plus'].median().sort_values(ascending=False)\n",
    "\n",
    "# Map the median values to the dataframe\n",
    "df_2024_pd['tj_stuff_plus_median'] = df_2024_pd['pitch_type'].map(median_values.to_dict())\n",
    "\n",
    "# Sort the dataframe by the median values of tj_stuff_plus\n",
    "df_2024_pd = df_2024_pd.sort_values(by='tj_stuff_plus_median', ascending=False)\n",
    "\n",
    "# Create a subplot for the boxen plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot the boxen plot of tj_stuff_plus for specific pitch types, colored by pitch type\n",
    "bp = sns.boxenplot(data=df_2024_pd[df_2024_pd['pitch_type'].isin(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])], \n",
    "               x='tj_stuff_plus', \n",
    "               y='pitch_type',\n",
    "               palette=dict_colour,\n",
    "               ax=ax,\n",
    "               showfliers=False,  # Do not show outliers\n",
    "               k_depth=6          # Number of boxes to draw\n",
    "               )\n",
    "\n",
    "bp.set_yticklabels([dict_pitch[x.get_text()] + f' ({x.get_text()})' for x in bp.get_yticklabels()])\n",
    "\n",
    "\n",
    "# Annotate the median values on the plot\n",
    "for index, row in median_values.reset_index().iterrows():\n",
    "    ax.text(row['tj_stuff_plus'], \n",
    "            index, \n",
    "            f'{row[\"tj_stuff_plus\"]:.0f}', \n",
    "            color='black', \n",
    "            ha=\"center\", \n",
    "            va=\"center\",\n",
    "            bbox=dict(facecolor='white', alpha=1,edgecolor='k')  # White background for the text\n",
    "            )\n",
    "\n",
    "# Set the x-axis limits\n",
    "ax.set_xlim(60, 140)\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('tjStuff+ Distribution and Median by Pitch Type - 2024 Season')\n",
    "\n",
    "# Set the x-axis and y-axis label\n",
    "ax.set_xlabel('tjStuff+')\n",
    "ax.set_ylabel('Pitch Type')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch data from Fangraphs API for the 2023 and 2024 MLB seasons\n",
    "data = requests.get(\"https://www.fangraphs.com/api/leaders/major-league/data?age=&pos=all&stats=pit&lg=all&season=2024&season1=2024&ind=1&qual=0&type=8&month=0&pageitems=500000\").json()\n",
    "\n",
    "# Define the schema explicitly for the incoming data\n",
    "schema = {\n",
    "    'playerid': pl.Int64,\n",
    "    'xMLBAMID': pl.Int64,\n",
    "    'PlayerName': pl.Utf8,\n",
    "    'Season': pl.Int64,\n",
    "    'Team': pl.Utf8,\n",
    "    'G': pl.Int64,\n",
    "    'IP': pl.Float64,\n",
    "    'K-BB%': pl.Float64,\n",
    "    'ERA': pl.Float64,\n",
    "    'FIP': pl.Float64,\n",
    "    'xFIP': pl.Float64,\n",
    "    'TBF': pl.Int64,\n",
    "    'Pitches': pl.Int64,\n",
    "}\n",
    "\n",
    "# Create a Polars DataFrame from the fetched data\n",
    "df_fg = pl.DataFrame(data=data['data'], schema=schema)\n",
    "\n",
    "# Load wOBA data from a CSV file\n",
    "df_woba = pl.read_csv('woba_2020_2024.csv')\n",
    "\n",
    "# Join the Fangraphs data with the wOBA data on player ID and season\n",
    "df_fg = df_fg.join(df_woba, left_on=['xMLBAMID', 'Season'], right_on=['player_id', 'year'], how='left')\n",
    "\n",
    "\n",
    "# Join the Fangraphs data with itself to get the previous season's data\n",
    "df_join = df_fg.join(df_agg_2024, left_on=['xMLBAMID', 'Season'], right_on=['pitcher_id', 'year'], how='inner', suffix='_2023')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the minimum number of pitches required for filtering\n",
    "min_pitches = 100\n",
    "\n",
    "# Filter the DataFrame to include only rows where the count and Pitches are greater than or equal to min_pitches\n",
    "df_join_filter = df_join.filter(\n",
    "    (pl.col('count') >= min_pitches) & (pl.col('Pitches') >= min_pitches)\n",
    ")\n",
    "\n",
    "# Print the minimum pitches, sample size, and average pitches\n",
    "print('Minimum Pitches:', min_pitches)\n",
    "print('Sample Size:', len(df_join_filter))\n",
    "print('Average Pitches:', int(df_join_filter['Pitches'].mean()))\n",
    "\n",
    "# Calculate and print the correlation between 2024 metrics\n",
    "print('Correlation between 2024 metrics:')\n",
    "corr_df = df_join_filter.to_pandas()[[\n",
    "    'tj_stuff_plus', 'FIP', 'woba', 'K-BB%'\n",
    "]].corr()[[\n",
    "    'tj_stuff_plus', 'FIP', 'woba', 'K-BB%'\n",
    "]].loc[\n",
    "    ['tj_stuff_plus', 'FIP', 'woba', 'K-BB%']\n",
    "].abs().round(2)\n",
    "\n",
    "# Rename the index and columns for better readability\n",
    "corr_df.index = ['2024 tjStuff+', '2024 FIP', '2024 wOBA', '2024 K-BB%']\n",
    "corr_df.columns = ['2024 tjStuff+', '2024 FIP', '2024 wOBA', '2024 K-BB%']\n",
    "\n",
    "# Display the correlation DataFrame\n",
    "corr_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024 Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained and validated, we can now apply it to 2024 data to get all sorts of metrics! Let's take a look at tjStuff+ by pitcher and pitch type and create a leaderboard.\n",
    "\n",
    "This code block aggregates tjStuff+ by Pitcher and pitch type. To better contextualize tjStuff+, I also calculate a 'Pitch Grade' for each pitch type which is scaled to the traditional 20-80 Scouting Grades. It is normally distributed, however the Standard Deviation () is determined by taking the difference between the 99.9th and 0.1th Percentile of tjStuff+. This ensures that the greatest tjStuff+ pitch of a specific type is graded at 80, while the worst tjStuff+ pitch is graded at 20.\n",
    "\n",
    "I decided to make it like this because applying the Standard deviation at the pitch level for each pitch type caused very tight distributions, especially for 4-Seam Fastballs. The greatest 4-Seam \"Pitch Grade\" for this method was 65. While it is mathematically sound, having the best Fastballs in baseball graded as \"Good\" rather than \"Elite\" did not sit well with me.\n",
    "\n",
    "Each pitch type has pitches that can span from 20 to 80 in grade, with grades following a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "def pitch_agg(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Group by pitcher_id, pitcher_name, and year, then aggregate to calculate the number of pitches, unique games, and mean tj_stuff_plus\n",
    "    df_plot = df.group_by(['pitcher_id', 'pitcher_name', 'year']).agg(\n",
    "        pl.col('tj_stuff_plus').len().alias('pitches'),\n",
    "        pl.col('game_id').n_unique().alias('games'),\n",
    "        pl.col('tj_stuff_plus').mean()\n",
    "    )\n",
    "\n",
    "    # Calculate pitches per game\n",
    "    df_plot = df_plot.with_columns(\n",
    "        (pl.col('pitches') / pl.col('games')).alias('pitches_per_game')\n",
    "    )\n",
    "\n",
    "    # Create a new column 'position' based on the condition: if pitches_per_game >= 40, then 'SP' (Starting Pitcher), else 'RP' (Relief Pitcher)\n",
    "    df_plot = df_plot.with_columns(\n",
    "        pl.when(pl.col('pitches_per_game') >= 40)\n",
    "        .then(pl.lit('SP'))\n",
    "        .otherwise(pl.lit('RP'))\n",
    "        .alias('position')\n",
    "    )\n",
    "\n",
    "    # Create a dictionary mapping pitcher_id to position\n",
    "    position_dict = dict(zip(df_plot['pitcher_id'], df_plot['position']))\n",
    "\n",
    "    # Add a column 'pitch_type' with a constant value 'All'\n",
    "    df_plot = df_plot.with_columns(\n",
    "        (pl.lit('All')).alias('pitch_type')\n",
    "    )\n",
    "\n",
    "    # Group by pitcher_id, pitcher_name, pitch_type, and year, then aggregate to calculate the number of pitches, unique games, and mean tj_stuff_plus\n",
    "    df_plot_pitch = df.group_by(['pitcher_id', 'pitcher_name', 'pitch_type', 'year']).agg(\n",
    "        pl.col('tj_stuff_plus').len().alias('pitches'),\n",
    "        pl.col('game_id').n_unique().alias('games'),\n",
    "        pl.col('tj_stuff_plus').mean()\n",
    "    )\n",
    "\n",
    "    # Concatenate the two DataFrames (df_plot and df_plot_pitch) into a single DataFrame\n",
    "    df_pitch_all_pd = pd.concat([df_plot.to_pandas(), df_plot_pitch.to_pandas()])\n",
    "    df_pitch_all = pl.DataFrame(df_pitch_all_pd)\n",
    "\n",
    "    # Filter and aggregate pitch types statistics\n",
    "    df_pitch_types = df_pitch_all.filter(pl.col('pitches') >= 10).to_pandas().groupby('pitch_type')['tj_stuff_plus'].agg(\n",
    "        mean='mean',\n",
    "        std='std',\n",
    "        median='median',\n",
    "        min='min',\n",
    "        max='max',\n",
    "        percentile_1=lambda x: x.quantile(0.001),\n",
    "        percentile_99=lambda x: x.quantile(0.999)\n",
    "    ).sort_values('mean', ascending=False).reset_index()\n",
    "\n",
    "    # Calculate standard deviation based on percentiles to scale it to the 20-80 Grade Scale\n",
    "    df_pitch_types['std'] = (df_pitch_types['percentile_99'] - df_pitch_types['percentile_1']) / 6\n",
    "    df_pitch_types.to_csv('tj_stuff_plus_pitch.csv', index=False, header=True)\n",
    "    df_pitch_types = pl.DataFrame(df_pitch_types)\n",
    "\n",
    "    # Join the pitch type statistics with the main DataFrame based on pitch_type\n",
    "    df_pitch_all = df_pitch_all.join(df_pitch_types, left_on='pitch_type', right_on='pitch_type')\n",
    "\n",
    "    # Normalize pitch_grade values to a range between -0.5 and 0.5 based on the percentiles\n",
    "    df_pitch_all = df_pitch_all.with_columns(\n",
    "        ((pl.col('tj_stuff_plus') - pl.col('mean')) / pl.col('std')).alias('pitch_grade')\n",
    "    )\n",
    "\n",
    "    # Scale the pitch_grade values to a range between 20 and 80\n",
    "    df_pitch_all = df_pitch_all.with_columns(\n",
    "        (pl.col('pitch_grade') * 10 + 50).clip(20, 80)\n",
    "    )\n",
    "\n",
    "    # Map the 'pitcher_id' to 'position' using the position_dict\n",
    "    df_pitch_all = df_pitch_all.with_columns(\n",
    "        df_pitch_all['pitcher_id'].map_elements(lambda x: position_dict.get(x, None)).alias('position')\n",
    "    )\n",
    "\n",
    "    # Filter the DataFrame to include only specific pitch types\n",
    "    df_pitch_all = df_pitch_all.filter(pl.col('pitch_type').is_in([\n",
    "        'FS', 'FO', 'SC', 'FF', 'SI', 'SV', 'KC', 'All', 'FC', 'SL', 'ST', 'CU', 'CH', 'KN'\n",
    "    ]))\n",
    "    \n",
    "    return df_plot, df_plot_pitch, df_pitch_all, position_dict\n",
    "\n",
    "# Call the pitch_agg function and store the results in df_plot, df_plot_pitch, and df_pitch_all\n",
    "df_plot, df_plot_pitch, df_pitch_all, position_dict = pitch_agg(df_2024)\n",
    "\n",
    "# Write the final DataFrame to a CSV file\n",
    "df_pitch_all.write_csv('tjstuff_plus_pitch_data_2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at tjStuff+ by position. Starters (SP) and Relievers (RP) play two distinct roles in baseball. Starters are tasked with pitching longer outings and are geared towards command and control rather than higher velocity and strikeout numbers. Relievers are quite the opposite, as they pitch shorter outings and tend to post incredible K% with less emphasis on lower BB%.\n",
    "\n",
    "This shows up in the distribution of tjStuff+ by SP and RP. SP are more clustered together with just a handful displaying elite stuff, while RP is positively skewed. Thanks to their shorter outing, RP can consistently output higher quality pitches, making both the average and the max greater than SP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the median of tj_stuff_plus for each pitch_type\n",
    "mean_values = df_plot.to_pandas().groupby('position')['tj_stuff_plus'].median().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Sort the dataframe by the median values of tj_stuff_plus\n",
    "df_2024_sp_rp = df_plot.filter(df_plot['pitches']>=100).to_pandas().sort_values(by='tj_stuff_plus', ascending=False)\n",
    "\n",
    "# Create a subplot for the boxen plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6),dpi=300)\n",
    "\n",
    "# Plot the boxen plot of tj_stuff_plus for specific pitch types, colored by pitch type\n",
    "bp = sns.boxenplot(data=df_2024_sp_rp, \n",
    "               x='tj_stuff_plus', \n",
    "               y='position',\n",
    "               ax=ax,\n",
    "               palette=[dict_colour[x] for x in dict_colour][7:9],\n",
    "               showfliers=True,  # Do not show outliers\n",
    "               k_depth=6          # Number of boxes to draw\n",
    "               )\n",
    "\n",
    "# Annotate the median values on the plot\n",
    "for index, row in mean_values.reset_index().iterrows():\n",
    "    ax.text(row['tj_stuff_plus'], \n",
    "            index, \n",
    "            f'{row[\"tj_stuff_plus\"]:.0f}', \n",
    "            color='black', \n",
    "            ha=\"center\", \n",
    "            va=\"center\",\n",
    "            bbox=dict(facecolor='white', alpha=1,edgecolor='k')  # White background for the text\n",
    "            )\n",
    "\n",
    "# Set the x-axis limits\n",
    "ax.set_xlim(80, 120)\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('Pitcher Level tjStuff+ Distribution and Median by Position (min. 100 Pitches) - 2024 Season')\n",
    "\n",
    "# Set the x-axis and y-axis label\n",
    "ax.set_xlabel('tjStuff+')\n",
    "ax.set_ylabel('Position')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graphic is a simple leader board of the best tjStuff+ pitchers during the 2024 MLB Season.It could be displayed in a table, but I like illustrating leader boards in different ways, such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import datetime\n",
    "\n",
    "# Select the statistic to display\n",
    "stat_select = 'tj_stuff_plus'\n",
    "\n",
    "# Number of top pitchers to display and minimum pitches required\n",
    "len_pit = 10\n",
    "min_pitch = 100\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = len_pit + 2  # 10 players + 2 for top and bottom\n",
    "num_cols = 3  # Three columns: two thin ones on the edges and one main column in the center\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(20, 20), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with different widths for the columns\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.5, 9, 0.5])\n",
    "\n",
    "# Create a new column 'picture' with the formatted URLs for pitcher images\n",
    "df_plot = df_plot.with_columns(\n",
    "    pl.col('pitcher_id').map_elements(lambda i: f'https://img.mlbstatic.com/mlb-photos/image/upload/w_180,d_people:generic:headshot:silo:current.png,q_auto:best,f_auto/v1/people/{i}/headshot/silo/current').alias('picture')\n",
    ")\n",
    "\n",
    "# Sort the dataframe in descending order based on the selected metric (tj_stuff_plus)\n",
    "sorted_df = df_plot.to_pandas()[df_plot.to_pandas()['pitches'] >= min_pitch].sort_values(by=stat_select, ascending=False)\n",
    "\n",
    "# Define the positions for the top 10 players in the grid\n",
    "positions = [(i + 1, 1) for i in range(len_pit)]\n",
    "\n",
    "# Iterate over the top 10 players in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(len_pit).iterrows()):\n",
    "    player = team_row['pitcher_name']\n",
    "    logo_url = team_row['picture']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    # img = plt.imread(logo_url)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    # ax.imshow(img, extent=[-0.6, -0.4, 0, 1], aspect=0.2)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the rank number to the left of the logo, italicized\n",
    "    ax.text(0.1, 0.5, f'{i + 1}', transform=ax.transAxes, ha='center', va='center', fontsize=36, style='italic')\n",
    "    \n",
    "    # Add the player name and metric value as text with bigger font size, bold the metric\n",
    "    ax.text(0.45, 0.5, f'{player}', transform=ax.transAxes, ha='left', va='center', fontsize=36, style='italic')\n",
    "    ax.text(0.9, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=36, weight='bold')\n",
    "\n",
    "# Adjust the spacing between subplots to place them on the borders\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "\n",
    "# Add text annotations at the bottom\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=24, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=24, ha='right')\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=16, ha='center')\n",
    "\n",
    "# Add the title at the top\n",
    "ax_top.text(s=f'tjStuff+ v3.0 Leaders - 2024 MLB Season - min. {min_pitch} Pitches', x=0.5, y=0.5, fontsize=36, ha='center', style='italic', weight='bold')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graphic is a leader board of the greatest tjStuff+ by Pitch Type. These pitches are assigned a \"Pitch Grade\" of 80 by our aforementioned definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import datetime\n",
    "\n",
    "# Constants\n",
    "stat_select = 'tj_stuff_plus'\n",
    "len_pit = 9\n",
    "min_pitch = 10\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = len_pit + 2  # 10 players + 2 for top and bottom\n",
    "num_cols = 3  # Three columns: two thin ones on the edges and one main column in the center\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(20, 20), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with different widths for the columns\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.5, 9, 0.5])\n",
    "\n",
    "# Filter and sort the dataframe\n",
    "df_pitch_all_best = df_pitch_all.filter(\n",
    "    (df_pitch_all['pitch_type'].is_in(['FF', 'SI', 'FC', 'SL', 'ST', 'CH', 'FS', 'CU', 'KC'])) &\n",
    "    (df_pitch_all['pitches'] >= 150)\n",
    ").sort('pitch_grade', descending=True).unique(subset=['pitch_type']).sort('pitch_grade', descending=True)\n",
    "\n",
    "# Add pitcher image URLs\n",
    "df_pitch_all_best = df_pitch_all_best.with_columns(\n",
    "    pl.col('pitcher_id').map_elements(lambda i: f'https://img.mlbstatic.com/mlb-photos/image/upload/w_180,d_people:generic:headshot:silo:current.png,q_auto:best,f_auto/v1/people/{i}/headshot/silo/current').alias('picture')\n",
    ")\n",
    "\n",
    "# Convert to pandas and filter based on minimum pitches\n",
    "sorted_df = df_pitch_all_best.to_pandas()[df_pitch_all_best.to_pandas()['pitches'] >= min_pitch].sort_values(by=stat_select, ascending=False)\n",
    "sorted_df['pitch_description'] = sorted_df['pitch_type'].map(dict_pitch)\n",
    "\n",
    "# Define the positions for the inner 10 plots in the main column\n",
    "positions = [(i + 1, 1) for i in range(len_pit)]\n",
    "\n",
    "# Iterate over the top 10 players in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(len_pit).iterrows()):\n",
    "    player = team_row['pitcher_name']\n",
    "    logo_url = team_row['picture']\n",
    "    pitch_name = team_row['pitch_description']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    # img = plt.imread(logo_url)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    # ax.imshow(img, extent=[-0.4, -0.2, 0, 1], aspect=0.2)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the pitch description, player name, and metric value\n",
    "    ax.text(0.1, 0.5, f'{pitch_name}', transform=ax.transAxes, ha='center', va='center', fontsize=36, style='italic', weight='bold', color=dict_colour[team_row['pitch_type']])\n",
    "    ax.text(0.45, 0.5, f'{player}', transform=ax.transAxes, ha='left', va='center', fontsize=36, style='italic')\n",
    "    ax.text(0.9, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=36, weight='bold')\n",
    "\n",
    "# Add top and bottom text\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=24, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=24, ha='right')\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=16, ha='center')\n",
    "\n",
    "# Add the main title\n",
    "ax_top.text(s=f'Highest tjStuff+ by Pitch Type - 2024 MLB Season - min. {min_pitch} Pitches', x=0.5, y=0.5, fontsize=36, ha='center', style='italic', weight='bold')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a [Streamlit App](https://tjstatsapps-tjstuffplus.hf.space/) which tabulates and plots tjStuff+ for all MLB players during the 2024 MLB Season.\n",
    "\n",
    "Here is an example\n",
    "\n",
    "!['Tyler Glasnow'](image/glasnow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate some team metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of MLB teams and their corresponding ESPN logo URLs\n",
    "mlb_teams = [\n",
    "    {\"team\": \"AZ\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/ari.png&h=500&w=500\"},\n",
    "    {\"team\": \"ATL\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/atl.png&h=500&w=500\"},\n",
    "    {\"team\": \"BAL\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/bal.png&h=500&w=500\"},\n",
    "    {\"team\": \"BOS\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/bos.png&h=500&w=500\"},\n",
    "    {\"team\": \"CHC\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/chc.png&h=500&w=500\"},\n",
    "    {\"team\": \"CWS\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/chw.png&h=500&w=500\"},\n",
    "    {\"team\": \"CIN\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/cin.png&h=500&w=500\"},\n",
    "    {\"team\": \"CLE\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/cle.png&h=500&w=500\"},\n",
    "    {\"team\": \"COL\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/col.png&h=500&w=500\"},\n",
    "    {\"team\": \"DET\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/det.png&h=500&w=500\"},\n",
    "    {\"team\": \"HOU\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/hou.png&h=500&w=500\"},\n",
    "    {\"team\": \"KC\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/kc.png&h=500&w=500\"},\n",
    "    {\"team\": \"LAA\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/laa.png&h=500&w=500\"},\n",
    "    {\"team\": \"LAD\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/lad.png&h=500&w=500\"},\n",
    "    {\"team\": \"MIA\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/mia.png&h=500&w=500\"},\n",
    "    {\"team\": \"MIL\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/mil.png&h=500&w=500\"},\n",
    "    {\"team\": \"MIN\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/min.png&h=500&w=500\"},\n",
    "    {\"team\": \"NYM\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/nym.png&h=500&w=500\"},\n",
    "    {\"team\": \"NYY\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/nyy.png&h=500&w=500\"},\n",
    "    {\"team\": \"OAK\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/oak.png&h=500&w=500\"},\n",
    "    {\"team\": \"PHI\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/phi.png&h=500&w=500\"},\n",
    "    {\"team\": \"PIT\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/pit.png&h=500&w=500\"},\n",
    "    {\"team\": \"SD\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/sd.png&h=500&w=500\"},\n",
    "    {\"team\": \"SF\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/sf.png&h=500&w=500\"},\n",
    "    {\"team\": \"SEA\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/sea.png&h=500&w=500\"},\n",
    "    {\"team\": \"STL\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/stl.png&h=500&w=500\"},\n",
    "    {\"team\": \"TB\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/tb.png&h=500&w=500\"},\n",
    "    {\"team\": \"TEX\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/tex.png&h=500&w=500\"},\n",
    "    {\"team\": \"TOR\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/tor.png&h=500&w=500\"},\n",
    "    {\"team\": \"WSH\", \"logo_url\": \"https://a.espncdn.com/combiner/i?img=/i/teamlogos/mlb/500/scoreboard/wsh.png&h=500&w=500\"}\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_image = pl.DataFrame(mlb_teams)\n",
    "image_dict = dict(zip(df_image['team'], df_image['logo_url']))\n",
    "\n",
    "# Nap positions to the dataframe\n",
    "df_2024 = df_2024.with_columns(\n",
    "    pl.col('pitcher_id').map_elements(lambda x: position_dict.get(x, x)).alias('position')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a leader board for tjStuff+ by team. I will also show tjStuff+ for Starters and Relievers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Group by pitcher_team and aggregate to calculate the number of pitches and mean tj_stuff_plus\n",
    "df_plot_team = df_2024.group_by(['pitcher_team']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('pitches'),\n",
    "    pl.col('tj_stuff_plus').mean(),\n",
    ")\n",
    "\n",
    "# Map team logos to the dataframe\n",
    "df_plot_team = df_plot_team.with_columns(\n",
    "    pl.col('pitcher_team').map_elements(lambda x: image_dict.get(x, x)).alias('logo')\n",
    ")\n",
    "\n",
    "stat_select = 'tj_stuff_plus'\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = 13\n",
    "num_cols = 7  # Updated to 7 columns\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(25, 25), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with specified column ratios\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.01, 0.4, 0.1, 0.4, 0.1, 0.4, 0.01])\n",
    "\n",
    "# Sort the dataframe in descending order based on the metric (tj_stuff_plus)\n",
    "sorted_df = df_plot_team.to_pandas().sort_values(by=stat_select, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Define the positions for the inner 30 plots\n",
    "positions_left = [(i + 1, 1) for i in range(10)]\n",
    "positions_middle = [(i + 1, 3) for i in range(10)]\n",
    "positions_right = [(i + 1, 5) for i in range(10)]\n",
    "\n",
    "# Combine positions for left, middle, and right sides\n",
    "positions = positions_left + positions_middle + positions_right\n",
    "\n",
    "# Iterate over the top 30 teams in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(30).iterrows()):\n",
    "    logo_url = team_row['logo']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    # img = plt.imread(logo_url)\n",
    "    # ax.imshow(img, extent=[0.3, 0.8, 0.3, 0.8], origin='upper')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the rank number to the left of the logo, italicized\n",
    "    ax.text(-1, 0.5, f'{i + 1}', transform=ax.transAxes, ha='center', va='center', fontsize=48, style='italic')\n",
    "    \n",
    "    # Add the team name and metric value as text with bigger font size, bold the metric\n",
    "    ax.text(1.6, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=48, weight='bold')\n",
    "\n",
    "# Adjust the spacing between subplots to place them on the borders\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_info = fig.add_subplot(gs[-2, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "ax_info.axis('off')\n",
    "\n",
    "ax_middle = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# Add title and additional information\n",
    "ax_middle.set_title(label=f'tjStuff+ by Team - 2024 MLB Season', x=0.5, y=0, fontsize=56, ha='center', va='bottom', style='italic', weight='bold')\n",
    "ax_middle.axis('off')\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=24, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=24, ha='right')\n",
    "\n",
    "import datetime\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=12, ha='center')\n",
    "\n",
    "ax_info.text(x=0.5, y=0, s='tjStuff+ calculates the Expected Run Value (xRV) of a pitch regardless of type\\n'\n",
    "                            'tjStuff+ is normally distributed, where 100 is the mean and Standard Deviation is 10\\n',\n",
    "                            ha='center', va='bottom', fontsize=24, style='italic')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Filter the dataframe for starting pitchers (SP) and group by pitcher_team\n",
    "df_plot_team_sp = df_2024.filter(df_2024['position'] == 'SP').group_by(['pitcher_team']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('pitches'),\n",
    "    pl.col('tj_stuff_plus').mean(),\n",
    ")\n",
    "\n",
    "# Map team logos to the dataframe\n",
    "df_plot_team_sp = df_plot_team_sp.with_columns(\n",
    "    pl.col('pitcher_team').map_elements(lambda x: image_dict.get(x, x)).alias('logo')\n",
    ")\n",
    "\n",
    "stat_select = 'tj_stuff_plus'\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = 13\n",
    "num_cols = 7  # Updated to 7 columns\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(25, 25), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with specified column ratios\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.01, 0.4, 0.1, 0.4, 0.1, 0.4, 0.01])\n",
    "\n",
    "# Sort the dataframe in descending order based on the metric (tj_stuff_plus)\n",
    "sorted_df = df_plot_team_sp.to_pandas().sort_values(by=stat_select, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Define the positions for the inner 30 plots\n",
    "positions_left = [(i + 1, 1) for i in range(10)]\n",
    "positions_middle = [(i + 1, 3) for i in range(10)]\n",
    "positions_right = [(i + 1, 5) for i in range(10)]\n",
    "\n",
    "# Combine positions for left, middle, and right sides\n",
    "positions = positions_left + positions_middle + positions_right\n",
    "\n",
    "# Iterate over the top 30 teams in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(30).iterrows()):\n",
    "    logo_url = team_row['logo']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    img = plt.imread(logo_url)\n",
    "    ax.imshow(img, extent=[0.3, 0.8, 0.3, 0.8], origin='upper')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the rank number to the left of the logo, italicized\n",
    "    ax.text(-1, 0.5, f'{i + 1}', transform=ax.transAxes, ha='center', va='center', fontsize=48, style='italic')\n",
    "    \n",
    "    # Add the team name and metric value as text with bigger font size, bold the metric\n",
    "    ax.text(1.6, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=48, weight='bold')\n",
    "\n",
    "# Adjust the spacing between subplots to place them on the borders\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_info = fig.add_subplot(gs[-2, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "ax_info.axis('off')\n",
    "\n",
    "ax_middle = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# Add title and additional information\n",
    "ax_middle.set_title(label=f'tjStuff+ by Team Starters - 2024 MLB Season', x=0.5, y=0, fontsize=56, ha='center', va='bottom', style='italic', weight='bold')\n",
    "ax_middle.axis('off')\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=24, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=24, ha='right')\n",
    "\n",
    "import datetime\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=12, ha='center')\n",
    "\n",
    "ax_info.text(x=0.5, y=0, s='tjStuff+ calculates the Expected Run Value (xRV) of a pitch regardless of type\\n'\n",
    "                            'tjStuff+ is normally distributed, where 100 is the mean and Standard Deviation is 10\\n',\n",
    "                            ha='center', va='bottom', fontsize=24, style='italic')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Filter the dataframe for relief pitchers (RP) and group by pitcher_team\n",
    "df_plot_team_rp = df_2024.filter(df_2024['position'] == 'RP').group_by(['pitcher_team']).agg(\n",
    "    pl.col('tj_stuff_plus').len().alias('pitches'),\n",
    "    pl.col('tj_stuff_plus').mean(),\n",
    ")\n",
    "\n",
    "# Map team logos to the dataframe\n",
    "df_plot_team_rp = df_plot_team_rp.with_columns(\n",
    "    pl.col('pitcher_team').map_elements(lambda x: image_dict.get(x, x)).alias('logo')\n",
    ")\n",
    "\n",
    "stat_select = 'tj_stuff_plus'\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = 13\n",
    "num_cols = 7  # Updated to 7 columns\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(25, 25), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with specified column ratios\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.01, 0.4, 0.1, 0.4, 0.1, 0.4, 0.01])\n",
    "\n",
    "# Sort the dataframe in descending order based on the metric (tj_stuff_plus)\n",
    "sorted_df = df_plot_team_rp.to_pandas().sort_values(by=stat_select, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Define the positions for the inner 30 plots\n",
    "positions_left = [(i + 1, 1) for i in range(10)]\n",
    "positions_middle = [(i + 1, 3) for i in range(10)]\n",
    "positions_right = [(i + 1, 5) for i in range(10)]\n",
    "\n",
    "# Combine positions for left, middle, and right sides\n",
    "positions = positions_left + positions_middle + positions_right\n",
    "\n",
    "# Iterate over the top 30 teams in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(30).iterrows()):\n",
    "    logo_url = team_row['logo']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    img = plt.imread(logo_url)\n",
    "    ax.imshow(img, extent=[0.3, 0.8, 0.3, 0.8], origin='upper')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the rank number to the left of the logo, italicized\n",
    "    ax.text(-1, 0.5, f'{i + 1}', transform=ax.transAxes, ha='center', va='center', fontsize=48, style='italic')\n",
    "    \n",
    "    # Add the team name and metric value as text with bigger font size, bold the metric\n",
    "    ax.text(1.6, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=48, weight='bold')\n",
    "\n",
    "# Adjust the spacing between subplots to place them on the borders\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_info = fig.add_subplot(gs[-2, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "ax_info.axis('off')\n",
    "\n",
    "ax_middle = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# Add title and additional information\n",
    "ax_middle.set_title(label=f'tjStuff+ by Team Relievers - 2024 MLB Season', x=0.5, y=0, fontsize=56, ha='center', va='bottom', style='italic', weight='bold')\n",
    "ax_middle.axis('off')\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=24, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=24, ha='right')\n",
    "\n",
    "import datetime\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=12, ha='center')\n",
    "\n",
    "ax_info.text(x=0.5, y=0, s='tjStuff+ calculates the Expected Run Value (xRV) of a pitch regardless of type\\n'\n",
    "                            'tjStuff+ is normally distributed, where 100 is the mean and Standard Deviation is 10\\n',\n",
    "                            ha='center', va='bottom', fontsize=24, style='italic')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the distribution of tjStuff+ as we aggregate to different levels. Recall, tjStuff+ is normally distributed with a mean of 100 and a standard deviation of 10 at the pitch level. As we aggregate, we deal with larger and larger samples which regresses tjStuff+ to the mean. I do not scale tjStuff+ after aggregation, so it is important to understand how the distribution of tjStuff+ varies at different aggregation levels.\n",
    "\n",
    "The following plot illustrates how the distribution of tjStuff+ tighten as we aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the color list for the plots\n",
    "color_list = [dict_colour[x] for x in dict_colour]\n",
    "\n",
    "# Sort the dataframe by the median values of tj_stuff_plus\n",
    "df_2024_sp_rp = df_plot_team.to_pandas().sort_values(by='tj_stuff_plus', ascending=False)\n",
    "\n",
    "# Create a subplot for the KDE plots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6), dpi=300)\n",
    "\n",
    "# Plot the KDE of tj_stuff_plus at the pitch level\n",
    "df_2024['tj_stuff_plus'].to_pandas().plot.kde(bw_method=0.8, color=color_list[7])\n",
    "\n",
    "# Plot the KDE of tj_stuff_plus at the pitcher level\n",
    "df_pitch_all.filter((df_pitch_all['pitch_type'] == 'All') & (df_pitch_all['pitches'] >= 100))['tj_stuff_plus'].to_pandas().plot.kde(bw_method=0.8, color=color_list[8])\n",
    "\n",
    "# Plot the KDE of tj_stuff_plus at the team level\n",
    "df_plot_team['tj_stuff_plus'].to_pandas().plot.kde(bw_method=0.8, color=color_list[1])\n",
    "\n",
    "# Set the x-axis limits\n",
    "ax.set_xlim(60, 140)\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('tjStuff+ Scales\\nBy: Thomas Nestico, Data: MLB', fontsize=24)\n",
    "\n",
    "# Set the x-axis and y-axis labels\n",
    "ax.set_xlabel('tjStuff+')\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend([f\"Pitch Level -  = {df_2024['tj_stuff_plus'].std():.1f}\",\n",
    "           f\"Pitcher Level -  = {df_pitch_all.filter((df_pitch_all['pitch_type'] == 'All') & (df_pitch_all['pitches'] >= 100))['tj_stuff_plus'].std():.1f}\",\n",
    "           f\"Team Level -  = {df_plot_team['tj_stuff_plus'].std():.1f}\"])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Park Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The physical characteristics of a pitch can vary depending on the environment. The most popular example of this is Coors Field in Colorado which is notorious for its extreme elevation, sitting 5200 ft above seas level. Due to this elevation, the air is less dense Colorado, which causes pitches to have less overall movement. This causes pitches in Colorado to be negatively affected in the calculation of tjStuff+.\n",
    "\n",
    "The way I calculate the park factors is first computing each teams tjStuff+ at home and on the road. After than I transform the tjStuff+ values into respective Z-Score and then Calculate the CDF probability. Finally, I divide Home CDF by Road CDF and multiply by 100 to get the Park Factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Polars DataFrame to a Pandas DataFrame for further processing\n",
    "df_2024_pd_pf = df_2024.to_pandas()\n",
    "\n",
    "# Create a dictionary to map game_id to the home team\n",
    "home_dict_id = df_2024_pd_pf.sort_values(by=['game_id', 'start_time']).groupby(['game_id']).head(1).set_index(['game_id'])['pitcher_team'].to_dict()\n",
    "\n",
    "# Map the home team to each row in the dataframe\n",
    "df_2024_pd_pf['home'] = df_2024_pd_pf['game_id'].map(home_dict_id).astype(str)\n",
    "\n",
    "# Determine if the pitcher is playing at home\n",
    "df_2024_pd_pf['pitcher_home'] = df_2024_pd_pf['home'] == df_2024_pd_pf['pitcher_team']\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_probability(z_score):\n",
    "    \"\"\"\n",
    "    Calculate the cumulative distribution function (CDF) for a given z-score.\n",
    "    \"\"\"\n",
    "    probability = stats.norm.cdf(z_score)\n",
    "    return probability\n",
    "\n",
    "# Step 1: Calculate the home and away means\n",
    "grouped_means = df_2024_pd_pf.groupby(['pitcher_team', 'pitcher_home'])['tj_stuff_plus'].mean().unstack()\n",
    "\n",
    "# Step 2: Compute the park factors\n",
    "# Assumption: True = Home, False = Away\n",
    "grouped_means['target_true'] = (grouped_means[True] - 100) / 10\n",
    "grouped_means['target_false'] = (grouped_means[False] - 100) / 10\n",
    "grouped_means['false_prob'] = grouped_means['target_true'].apply(calculate_probability)\n",
    "grouped_means['true_prob'] = grouped_means['target_false'].apply(calculate_probability)\n",
    "grouped_means['park_factor'] = abs(grouped_means['false_prob'] / grouped_means['true_prob']) * 100\n",
    "\n",
    "# Convert the grouped_means DataFrame to a Polars DataFrame\n",
    "grouped_means = pl.DataFrame(grouped_means.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot Park Factors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Map team logos to the dataframe\n",
    "grouped_means = grouped_means.with_columns(\n",
    "    pl.col('pitcher_team').map_elements(lambda x: image_dict.get(x, x)).alias('logo')\n",
    ")\n",
    "\n",
    "stat_select = 'park_factor'\n",
    "\n",
    "# Set the number of rows and columns for the subplot grid\n",
    "num_rows = 13\n",
    "num_cols = 7  # Updated to 7 columns\n",
    "\n",
    "# Set the font style to Calibri\n",
    "plt.rcParams['font.family'] = 'calibri'\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(25, 25), dpi=300)\n",
    "\n",
    "# Create a GridSpec object with specified column ratios\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, width_ratios=[0.01, 0.4, 0.1, 0.4, 0.1, 0.4, 0.01])\n",
    "\n",
    "# Sort the dataframe in descending order based on the metric (park_factor)\n",
    "sorted_df = grouped_means.to_pandas().sort_values(by=stat_select, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Define the positions for the inner 30 plots\n",
    "positions_left = [(i + 1, 1) for i in range(10)]\n",
    "positions_middle = [(i + 1, 3) for i in range(10)]\n",
    "positions_right = [(i + 1, 5) for i in range(10)]\n",
    "\n",
    "# Combine positions for left, middle, and right sides\n",
    "positions = positions_left + positions_middle + positions_right\n",
    "\n",
    "# Iterate over the top 30 teams in the sorted dataframe\n",
    "for i, (_, team_row) in enumerate(sorted_df.head(30).iterrows()):\n",
    "    logo_url = team_row['logo']\n",
    "    \n",
    "    # Determine the position in the grid\n",
    "    row, col = positions[i]\n",
    "    \n",
    "    # Create a subplot in the GridSpec layout\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the team logo\n",
    "    img = plt.imread(logo_url)\n",
    "    ax.imshow(img, extent=[0.3, 0.8, 0.3, 0.8], origin='upper')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add the rank number to the left of the logo, italicized\n",
    "    ax.text(-1, 0.5, f'{i + 1}', transform=ax.transAxes, ha='center', va='center', fontsize=48, style='italic')\n",
    "    \n",
    "    # Add the team name and metric value as text with bigger font size, bold the metric\n",
    "    ax.text(1.6, 0.5, f'{team_row[stat_select]:.0f}', transform=ax.transAxes, ha='left', va='center', fontsize=48, weight='bold')\n",
    "\n",
    "# Adjust the spacing between subplots to place them on the borders\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "ax_info = fig.add_subplot(gs[-2, :])\n",
    "ax_bot = fig.add_subplot(gs[-1, :])\n",
    "ax_left = fig.add_subplot(gs[:, 0])\n",
    "ax_right = fig.add_subplot(gs[:, -1])\n",
    "\n",
    "ax_top.axis('off')\n",
    "ax_bot.axis('off')\n",
    "ax_left.axis('off')\n",
    "ax_right.axis('off')\n",
    "ax_info.axis('off')\n",
    "\n",
    "ax_middle = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# Add title and additional information\n",
    "ax_middle.set_title(label=f'tjStuff+ Park Factors - 2024 MLB Season', x=0.5, y=0, fontsize=56, ha='center', va='bottom', style='italic', weight='bold')\n",
    "ax_middle.axis('off')\n",
    "ax_bot.text(s='By: @TJStats', x=0.1, y=0.5, fontsize=32, ha='left')\n",
    "ax_bot.text(s='Data: MLB', x=0.9, y=0.5, fontsize=32, ha='right')\n",
    "\n",
    "import datetime\n",
    "ax_bot.text(s=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}\", x=0.5, y=0.5, fontsize=18, ha='center')\n",
    "\n",
    "ax_info.text(x=0.5, y=0, s='''tjStuff+ Park Factors show the observed effect of tjStuff+ in the selected park\n",
    "                            Park Factors are calculated by comparing Home tjStuff+ and Away tjStuff+ at the pitch level''',\n",
    "                            ha='center', va='bottom', fontsize=24, style='italic')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
